{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The MNIST\n",
    "MNIST is a simple computer vision dataset. It consists of images of handwritten digits and labels for each image. You may meet warning after running the first line code. It doesn't impact the result of exercise.\n",
    "\n",
    "#### 1.1 MNIST Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Shape of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data X : (55000, 784)\n",
      "Training Data Y : (55000, 10)\n",
      "Test Data X : (10000, 784)\n",
      "Test Data Y : (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Training Data X :\", np.vstack([img.reshape(-1,) for img in mnist.train.images]).shape)\n",
    "print(\"Training Data Y :\", mnist.train.labels.shape)\n",
    "print(\"Test Data X :\", np.vstack([img.reshape(-1,) for img in mnist.test.images]).shape)\n",
    "print(\"Test Data Y :\", mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Data Visualization\n",
    "\n",
    "If image doesn't come out, please run below code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAADHCAYAAADGSF66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xe4VMX9x/H3VxQbWBA0VwSRiBoeYgSvJbH8YoyKBOSnKOqTIFbUxJpogiUajSbGWFCTqFix5Cf4WMBeSBBNLJRo0GABlSKImliwRmR+f9yds2dv3XJ2ztnl83oen3vunL27c/m4d3bmzJkx5xwiIiIhrZZ2BUREZNWjxkdERIJT4yMiIsGp8RERkeDU+IiISHBqfEREJDg1PiIiElxFjY+ZDTazV8xsnpmNTapSkgzlk23KJ7uUTfVZuTeZmlkn4FVgL2AxMAM41Dn3r+SqJ+VSPtmmfLJL2YSxegU/uyMwzzn3OoCZ3QEMB9oMqHv37q5Pnz4VvGT9mDVr1nvOuR5VfImS8lE2eQGyAeVTtqy9d0D5xBWbTyWNT09gUez7xcBOzR9kZmOAMQC9e/dm5syZFbxk/TCzBVV+iQ7zUTatC5ANKJ+yZeG9k6uH8mlFsflUcs3HWilrMYbnnBvvnGt0zjX26FHtD5MS02E+yiZVyie79LctgEoan8VAr9j3mwFLKquOJEj5ZJvyyS5lE0Aljc8MoJ+ZbWFmnYFDgCnJVEsSoHyyTflkl7IJoOxrPs65FWZ2AvAI0Am40Tn3UmI1k4oon2xTPtlVr9lcd911APz5z38G4Nprr43ObbXVVsHrU8mEA5xzDwIPJlQXSZjyyTblk13KpvoqanxERCR7nn/+eQBuuOGGqGz8+PEArFixAoB//vOf0bk0ej5aXkdERIJT4yMiIsHV7LDbp59+Gh3vtttuAPTv3x+AW2+9NZU6SXk+/PBDAKZNmxaV7bHHHgCst956aVRJpOY899xz0fGIESMAeOutt6Iys6bbl4YNGwbk32NpUc9HRESCq9mez2effRYdz549G4D33nsPgOXLlyf2Ouuss0503KlTp8Sed1U1adKk6Pi2224D4NFHHwXgiy++iM6tueaaAAwePDgq+/nPfw7Ad77znarXs57F3x/f/OY3Abj44osBGDlyZCp1kvL5Hk88uyVLWt4TO2TIECA/CWGjjTYKULu2qecjIiLB1WzPx49fAqy11loALFy4EEj2OsGoUaOiY/9J4cQTT4zKNtlkEwDWXXfdxF6zHt19990AHHLIIVGZ386jX79+AGyxxRbRub///e8ATJ48OSp74oknALj66qtbPJcU7/PPP4+OFyxoWgPyjDPOAGDttdeOzvle5xprrBGwdlKqU045BYBFixa1+7hrrrkGSL/H46nnIyIiwanxERGR4Gp22K1bt27R8RFHHAHkh2P69u0bnTvttNMAePvttwF45ZVXonPTp08HYPTo0VFZ7969C17Hd1UB3n33XQAmTpwYlfmLd/vuu2+5v0pde/LJJwE499xzAdhyyy2jcz6vXXbZBcgPnwI8/fTTAJxwwglRmZ9YMm7cOKBwMsIGG2yQeN3r1dKlS1uUvf766wDst99+UdnAgQMBuPTSS4H0p+ZKIf+3avHixS3Offe73wXg5JNPjsp69uwZpF7FUs9HRESCq9meT3saGxuj4+OPP76i56r051d1vpfiL4Y+/PDD0bmdd965zZ/79re/DeQ/dUP+U/mzzz4LwC233BKdO+mkkxKqcf174IEHWpT5nmZ8N86zzz4bgOHDhwNw9NFHR+f81OzVV6/LPyGZ49dqi/dMly1bBuQnX8UnPfkRHz+9OovU8xERkeDU+IiISHAd9pnN7EZgKPCOc25ArqwbMBHoA7wJjHTOvV+9apamT58+aVchmKzn45dt33333QEYNGhQST/vL5wCHHzwwQBcf/31ANx5553RuawOu2U9H2/zzTcHCodC/b+9H8K5/PLLo3Nz5swB4LHHHgtUw+TVSjaQX68yPrnAD7f5+xrj+WR5uM0rpudzMzC4WdlYYKpzrh8wNfe9pONmlE+W3YzyyaqbUTap6bDn45ybbmZ9mhUPB76bO54ATAN+kWC9OhRfn6r5p68BAwaErEqqspqP56dYH3nkkQBMnTo1Olfq9PSddtoJyPd8/CoIkL9g7icqZEUW8/FT1gG23nprALp27dricf595Fen8KshAzz++OMAnHrqqVGZn4RQKysiZDGb5ubPnw/Agw+23FTVTzDwPZ7DDz88WL2SUO41n02cc0sBcl83buuBZjbGzGaa2Ux/n4xUXVH5KJvUKJ/s0t+2QKo+T9I5Nx4YD9DY2OiSet6vvvoqOvb7wUhpqpVN3I9+9CMgvzp49+7dy36uvfbaq+D7lStXRsfx9crqRbXyifd8/B5YXbp0afPxPrvrrrsuKtt+++2B/FR6gGOPPRaAbbbZJqmqZlq18nnzzTej46FDhwLw6quvtnjctddeC8Chhx6a1EsHVW7PZ5mZNQDkvr6TXJUkAcon25RPdimbQMptfKYAfk2a0cDkdh4r4SmfbFM+2aVsAilmqvX/0XQBrruZLQbOBS4CJpnZUcBC4KBqVrI18bt5d911VwDuueee0NVIXVbzae6AAw5IuwqpyFI+fi3DN954Iyrzw27FiK+Z+Ktf/QrIL+cPtTf8naVs4uJr78XXooT8NiSQv32hVhUz262tAcU9E66LlEH5ZJvyyS5lk66aXZjpo48+io7b6/F88sknQOGaVc1tuOGG0fG2226bQO2kGl566aWC7+PrisW3O5fWrVixAshvUQ7w4x//uKzn8j3ZeM/nN7/5DZCffh2/cO4vmPuJCgAjRowo67Xr3QsvvBAdxzfNbM7fetCpU6c2HxPvKZ1zzjkArL/++gB88MEH0bkLLrigxeP9a/tert89IClaXkdERIKr2Z5Pe/w+MZC/GS6+AnJz8b1g/DIWfoqjJMN/Co5PkW+P743Gb3686KKLCh6zzz77RMf+U6C0zS+XE79Bu5RVqT/99NPoeMmSJS3OT5kyBYD77rsPKNyu2b/H4vs5Seva+1sV19q+TM3FezJ+Knyxj/c9nxtvvBFQz0dEROqAGh8REQmuZofd4utH+RV5FyxYAOTX+Yof+w3mvva1r0Xn/BRtvyYVwKhRowANv5XDrzIdX23aT+v1F1G//PLLop6roaEBgO222y4q81ty+yyvuuqqCmu8allttdUKvnbED5HOnTsXgJEjR0bnfFmcn8hw++23A7DDDjtE5/xFbv9VyuNXsIbCiVJtia8C4nP3q4G8807798/621l69OhRcj2LoZ6PiIgEV7M9n/gnAL93RXyigecvUvuLbfHJBd6mm24aHR922GFAvgcUn6L99a9/vdJq143PPvsMyK9WDTBx4kSg8KKl72luvHGb6zNGvaH4JzF/MbW1i6r+E9nHH39cVt2lbS+++GJ07N8Dfgvn+PpvftTgqaeeisoGD27anUBTqKtn8uT8ggv/8z//U9Zz+NEgn2Fbqr12nHo+IiISnBofEREJrmaH3doT30b7uOOOA9q/0Ln//vtHx36FA7/98xVXXBGdu/LKK5OsZk07/fTTAbjjjjuiMr8x2TXXXBOV+a59e/eT+Dut45vLPfPMMy0et9ZaawHwxBNPAPmJB5DfSCs+CaFz585F/CYS5++CB3j//abdo/3wy9577x2d+/e//w0UZhB/H0n54sPW8WMof6gN8lti+JUomj83wMCBA6Pjam/FrZ6PiIgEVxc9H393u1/H7cADD4zOFTO1M34htfkaYdqhsHWt/bs8+uijAPTu3buo5/B3zJ955plAYW/HT1A466yzorLvfe97ANx0001A4QST8ePHt6jX+eefD8BWW20FqCdUDL9ldkf8v3ecVplIRrz38dxzzxWc8/9PQ2EvFQpXoPATrPwoAcCyZcuA/Bp/8XXj/C0Nf/nLX6Kyak+LV89HRESCq4uez+jRowu+SvUtXLiwRZm/1nPaaadFZf7m0vnz5wP5db8gf13Nr/u28847R+f++Mc/AjBo0KAWr3PppZcC+et5kP+kF39+v9q5/yQZX8H56KOPbue3k9bMmTMnOvYZxHu5lWyRLnl+ijvkr7d58eupDz/8cMG5+A3cfqv01tZqGzZsGABnnHFGdM7nGPIm4A57PmbWy8z+amZzzewlMzs5V97NzB4zs9dyXzu+3VYSp3yyS9lkm/JJVzHDbiuAnznnvgHsDPzEzPoDY4Gpzrl+wNTc9xKe8skuZZNtyidFxexkuhRYmjtebmZzgZ7AcJq2oAWYAEwDflGVWlZZ/KKc767WirTy8ZME4nez//a3vy342pr4mnx+Y7ETTzwRKFzyPb5Nelv69esXHfsLpfELtPfeey+QXyWhtaml1VRv753XXnstOv7vf/8LwDHHHBOV1dqwW1bz8RNkIH/7wUMPPQTA22+/HZ3zEwiK5Sfo+PdsfMuLNJQ04cDM+gADgWeBTXLh+RBbXT/FzMaY2Uwzm6mZY9VVaj7KJhy9d7JN+YRnxX4aNLMuwBPAhc65u83sA+fcBrHz7zvn2h0bbWxsdO1tZ10pfxF8zz3zW7Dff//9QP4GyLjFixcD+TWpoOVWzTNmzIiO4zfUVcrMZjnnEnvCSvMpN5t4T9H/e7ZnwIAB0XHfvn1Lfr0QspYNVP+90x6/ZX18DUS/gvVbb70VlfmbgKttVcrHb/w3fPhwAKZNmxavd5s/5x+/++67R2V+kk381pJqKDafono+ZrYGcBdwu3PO3wiwzMwacucbgPbX55aqUT7ZpWyyTfmkp5jZbgbcAMx1zl0WOzUF8HObRwOTm/+sVJ/yyS5lk23KJ13F3OezCzAKmGNmz+fKzgQuAiaZ2VHAQuCg6lSxeF27dgUKu//+zt3NNtsMKOxyvvzyy0B+c6U4f9G8tftMMibVfOL/PjXwbxVazbx32nPJJZcA+RVEAM477zwg3FBblWQ+H/83Lb7yQL0oZrbbU0Bbg4t7tlEugSif7FI22aZ80lUXKxx4flvZqVOnRmV+PbDmEwna4jdH86slFLvlsEi98VN5r7/+egB69eoVnYvfhS9SDv1lFRGR4Oqq5+PFt2yObwssIsVbuXIlkL85N77tcnvboosUQz0fEREJTo2PiIgEV5fDbiJSuYaGBiC/Np5IktTzERGR4NT4iIhIcGp8REQkODU+IiISnBofEREJTo2PiIgEV/Rmcom8mNm7wCfAe8FeNHndSab+mzvneiTwPInIZbOA5H6/NNRlNqD3TjPKpzqC5hO08QEws5lJ7kIYWq3XvyO1/PvVct2LUeu/X63XvyO1/vuFrr+G3UREJDg1PiIiElwajc/4FF4zSbVe/47U8u9Xy3UvRq3/frVe/47U+u8XtP7Br/mIiIho2E1ERIIL2viY2WAze8XM5pnZ2JCvXSoz62VmfzWzuWb2kpmdnCvvZmaPmdlrua8bpl3XJNRSNqB80q5Pe5RNtmUmH+dckP+ATsB8oC/QGXgB6B/q9cuobwMwKHfcFXgV6A9cDIzNlY8Ffpd2XVe1bJRPtvNRNtnNJkv5hOz57AjMc8697pz7L3AHMDzg65fEObfUOTc7d7wcmAv0pKnOE3IPmwD8bzo1TFRNZQPKhwzno2yymw1kJ5+QjU9PYFHs+8W5sswzsz7AQOBZYBPn3FJoChGoh83sazYbUD5ZpmyyLc18QjY+1kpZ5qfamVkX4C7gFOfcR2nXp0pqMhtQPlmmbLIt7XxCNj6LgV6x7zcDlgR8/ZKZ2Ro0hXO7c+7uXPEyM2vInW8A3kmrfgmquWxA+aRUl6Iom2zLQj4hG58ZQD8z28LMOgOHAFMCvn5JzMyAG4C5zrnLYqemAKNzx6OByaHrVgU1lQ0oHzKcj7LJbjaQnXxCr2o9BBhH0wyRG51zFwZ78RKZ2a7Ak8AcYGWu+EyaxkYnAb2BhcBBzrn/pFLJBNVSNqB8spyPssluNpCdfLTCgYiIBKcVDkREJDg1PiIiEpwaHxERCU6Nj4iIBKfGR0REglPjIyIiwanxERGR4NT4iIhIcGp8REQkODU+IiISnBofEREJTo2PiIgEp8ZHRESCq6jxMbPBZvaKmc0zs7FJVUqSoXyyTflkl7KpvrK3VDCzTsCrwF407eY3AzjUOfev5Kon5VI+2aZ8skvZhLF6BT+7IzDPOfc6gJndAQwH2gyoe/furk+fPhW8ZP2YNWvWe865HlV8iZLyUTZ5AbIB5VO2rL13QPnEFZtPJY1PT2BR7PvFwE7NH2RmY4AxAL1792bmzJkVvGT9MLMFVX6JDvNRNq0LkA0on7Jl4b2Tq4fyaUWx+VRyzcdaKWsxhuecG++ca3TONfboUe0PkxLTYT7KJlXKJ7v0ty2AShqfxUCv2PebAUsqq44kSPlkm/LJLmUTQCWNzwygn5ltYWadgUOAKclUSxKgfLJN+WSXsgmg7Gs+zrkVZnYC8AjQCbjROfdSYjWTiiifbFM+2ZXlbA444IDo2KxpdPCuu+5KqzoVqWTCAc65B4EHE6qLJEz5ZJvyyS5lU30VNT4iIlJ9F1xwAQD33ntvVOZ7PrVKy+uIiEhwanxERCQ4DbuJiGTc5MmTASh3ObQsUs9HRESCq/uez/vvvw/AN77xDQA+++yz6NyLL74IQK9evVr+oCTqk08+AWD69OkVP9e+++5b8XOsilasWAHkP0UDLFy4EICTTjoJgE6dOrX584899lh0vPfeewNw2WWXRWWnnnpqcpUVAObOnQvAyy+/DBROMhgxYkQqdUqKej4iIhJcXfZ8/vOf/0THgwcPBmDZsmUtHvfhhx8Crfd8Pv/8cwAeeeSRqKxz586APnkDvPvuuwBceOGFLc7Fx6X9J7UPPvgAgNtvv73F47/66iug/U/dcVdeeSUAxx9/fAk1XjX5HifAbrvtBsDzzz8flfXs2RPI/z+9zTbbFPW8Ptc111wzkXpK68466ywgn2Pv3r2jc1dffXUqdUqKej4iIhKcGh8REQmuLofdLr744uh4xowZBedGjRoVHfthtFNOOSUqe+aZZwB44YUXgPzwW9xaa60VHZ9xxhkAnHPOOZVWO7Nee+216Piaa64B4J577gFg0aJFLR7vh9Gg+KG0UkyaNAmAQw89NCrbYIMNEn+dejBlSn49TD/cFs/k0ksvBYofbmtu+fLlFdROWuMnGUB+RQM/zBnfuqF79+5hK5Yw9XxERCS4uur5+GnV1113XYtzvsfjpywCbLvttgB88cUXLR7vezfDhg2LytZff30AhgwZEpXtv//+lVY787beeuvouNSezO677w7At771rTYf88YbbwBw//33F/WcCxY0bZQ4Z86cqMxfTJdC8U/R3qabbhodDx06tKLnf+655yr6eWnpsMMOi4795B3f47nllltSqVM1qOcjIiLBqfEREZHgOhx2M7MbgaHAO865AbmybsBEoA/wJjDSOfd+9apZnN///vdA4X0+nr9A/vHHH7c4F59AcNFFFwFw+OGHA/mhtqzKUj7nnXceAIMGDYrK+vfvDxTen9DcQw89BBQ/7OafsxaG2tLO5+STT46O/bL88UkiRx55JAB33HFHNV4+09LOprnmqxnk6gPkN5HzK7XUg2J6PjcDg5uVjQWmOuf6AVNz30s6bkb5ZNnNKJ+suhllk5oOez7Ouelm1qdZ8XDgu7njCcA04BcJ1qss119/fZvnfI9n3XXXjcr8JITTTz89Kuvbt2+ValcdIfJZuXJluT/awptvvhkdjxw5EshPh+9oc6wddtgBKL6HlAVZf//4CQN+ynTXrl3TqEYqspaNX8UgviqFn3BwzDHHhKhCUOVe89nEObcUIPd147YeaGZjzGymmc30S7JI1RWVj7JJjfLJLv1tC6TqU62dc+OB8QCNjY1BNqOIf3r74Q9/COSnC++3337RuVrr5SQtZDb+zemvMQD84x//API9no6mcft1yPyaVvW+tlsS+XTp0iU69itRP/roo1GZ74lOmDABgBNOOKHN53rqqadalMVvMvU3ZPtrqPFrr/5cfJp3rUv6/dP8hlLI3/xb7k3AWVZuz2eZmTUA5L6+k1yVJAHKJ9uUT3Ypm0DKbXymAKNzx6OBye08VsJTPtmmfLJL2QRSzFTr/6PpAlx3M1sMnAtcBEwys6OAhcBB1axksfbYYw+g8K7ucePGAfW79Hut5HPQQU1V+Nvf/lb2c9x3331AflMzny3kh+QmTpwYlcXXwUpL2vnE/7/fZZddgMJhN+/ss88G4F//+ldUdvTRRwOw5ZZbArDrrru2+LnHH388Op43b17BOb9BHcDGGzddOrntttuistVXT3eBlbSzae69994DCrck8etOrrPOOiU9l18F5Mknn4zK/LCpH8LbZ599onNpTOEuZrbboW2c2jPhukgZlE+2KZ/sUjbpqqu13S655BIABgwYEJX56bx+OnVjY2N0Ln5zqVTXjjvuCFTW8/H8VNTXX389KvPHBx98cFR20003AbD55ptX/Jr1wL8H4tPd/b/RRx99BORXLY8f77TTTkDhJ/LW+MkKs2bNAgqnDHt/+tOfouNu3bqVVP9653skHd1y0Nz48eOB/I30ALNnzwbyvSnI5+ef/5e//GV0zq9RGXLtOC2vIyIiwdVVz8dvh+2vCQCcf/75QH4plj59+kTnBg4cCMDYsfmbmP0ndEnWueeeC8Cnn34alflpt345nvgnviVLlgAwZsyYkl4nPsbtlylRz6eJ7+n/4Q9/iMr8uL+/PvPOOy0ndz377LNFPf/06dPbPOevyaV9nSfL/G0hV1xxRZuP8ddyIP+3ymcWf//4Xo6/1hZ/nBdfasxfi9tqq62iMn8dsFrU8xERkeDU+IiISHB12QeOD53deeedAMyfPx/Ir6AMsHTpUgC+//3vR2WXX345AEcddVTV67kq8WvqxYd8inHEEUe0eS6+YvNVV13V4rxfMy4+pVRg7bXXjo79hJxXX30VgAceeCA6V+xwW3N+Snd8evDvfvc7ANZbb72ynnNV4G8NaG977PjtA35I2g81x1fD9pOv/GaOUDj5APKrjgCMHt10a5PPCeDAAw8Eqre6gno+IiISnHU0fTJJjY2NbubMmcFer1h+uinAcccdB+Q/NfuttpNmZrOcc40dPzKMrGbTnvgFbj/FuvmnO4Avv/yypOfNWjYQLp/49OgXX3yx4Fx8y+x4r9Pba6+9AJg8uWlRgGrdylDv+fjV2yE/wcCP2Gy//faJvEZzP/3pT4H8yA/kp8zH9+cqRrH5qOcjIiLBqfEREZHg6nLCQan8umOQ32rYDx1Ua9hNKhdfjyp+EV3KF99s0a9s4PlVENqy0UYbAVo5pFLx/6/90NcPfvADoHCFCL+1dpJKXV2hEur5iIhIcOr5UHjh2q8R5rdqjq9/JOnyvVF/EdZvvgWwaNGiFo8fNmxYmIqJJCi+vlrz1alHjBgRnfM9Hz9aU+rK1Mcee2x07N9L8enxpa6kXSr1fEREJDj1fCicXujtuadWVQ/Nb48NhTc7en78e9myZUDH227HP9mJ1KLLLrsMgJ/97GdA4SiN7634/ZlKvRnUv58gf63n17/+dVRW7a27O+z5mFkvM/urmc01s5fM7ORceTcze8zMXst93bCqNZVWKZ/sUjbZpnzSVcyw2wrgZ865bwA7Az8xs/7AWGCqc64fMDX3vYSnfLJL2WSb8klRMTuZLgWW5o6Xm9lcoCcwnKYtaAEmANOAX1SlllXyyCOPAPDMM89EZaut1tQeV2MaYzVkMZ/4+nnXXnstAFOmTGnz8c03ueqIf/xXX33V4lx8y4z21sgKIYvZVMJviwD5pfpb24KhVtRCPn5Fg2nTpgFw9913R+f8emx+a4T4MFpr76nmZfHVbc466ywAzjzzzETr356SJhyYWR9gIPAssEkuPB/ixm38zBgzm2lmM+ML2UnySs1H2YSj9062KZ/wip5wYGZdgLuAU5xzH5XwKXU8MB6a1j8qp5JJ8puUQX7F5PimSkceeSRQuN12LSgnn6Sz8RMGfvKTn0RlflJAe5MDfA+mowkE7T3e93ImTJgQlVVrHaxS1ct7p3///tHxFltsART2fObNmwfkb4QcNWpUdK5r164hqliWWsonPiLj82ht8zk/4hDPzL9H/JRsv/p48+cNpaiej5mtQVM4tzvnfL9vmZk15M43ALXb/65xyie7lE22KZ/0FDPbzYAbgLnOuctip6YAo3PHo4HJyVdPOqJ8skvZZJvySVcxw267AKOAOWb2fK7sTOAiYJKZHQUsBA5q4+cT5e/03W677aKyLl26AK1fsP78888BuPXWWwE49dRTo3N++fgNNtggKqv2vuVVkJl8Wrs3pz2bbropkF+XrdjhDj+cdt5550Vla6yxBgC9e/cuqQ5VlplskubXfYtvOOe3FPBfhw4dGp3L6LBbTefj78OJ3x/ntVaWNcXMdnsKaOuvgu7ETJnyyS5lk23KJ101t8LB8uXLgcJptH41Av/pN87f/et7QHEbbth071j8E7u/kCql82up9evXLyprrzdzzDHHAKWvSSXp85suTpw4MSrzK0+IFENru4mISHA11/MZMmQIAE8//XRUNm7cOADeeustoHB82feQ/LRCv90ywP7771/dyq5itJbaqsNfb2hoaIjK1PORUqjnIyIiwanxERGR4Gpu2M0bNGhQdBzffElEwpk9e3baVZAapZ6PiIgEp8ZHRESCU+MjIiLBqfEREZHg1PiIiEhwanxERCQ4i2+lWvUXM3sX+AR4L9iLJq87ydR/c+dcjwSeJxG5bBaQ3O+XhrrMBvTeaUb5VEfQfII2PgBmNtM5V1vbhMbUev07Usu/Xy3XvRi1/vvVev07Uuu/X+j6a9hNRESCU+MjIiLBpdH4jE/hNZNU6/XvSC3/frVc92LU+u9X6/XvSK3/fkHrH/yaj4iIiIbdREQkODU+IiISXNDGx8wGm9krZjbPzMaGfO1SmVkvM/urmc01s5fM7ORceTcze8zMXst93TDtuiahlrIB5ZN2fdqjbLItM/k454L8B3QC5gN9gc7AC0AKTaBiAAABmklEQVT/UK9fRn0bgEG5467Aq0B/4GJgbK58LPC7tOu6qmWjfLKdj7LJbjZZyidkz2dHYJ5z7nXn3H+BO4DhAV+/JM65pc652bnj5cBcoCdNdZ6Qe9gE4H/TqWGiaiobUD5kOB9lk91sIDv5hGx8egKLYt8vzpVlnpn1AQYCzwKbOOeWQlOIwMbp1SwxNZsNKJ8sUzbZlmY+IRsfa6Us8/O8zawLcBdwinPuo7TrUyU1mQ0onyxTNtmWdj4hG5/FQK/Y95sBSwK+fsnMbA2awrndOXd3rniZmTXkzjcA76RVvwTVXDagfFKqS1GUTbZlIZ+Qjc8MoJ+ZbWFmnYFDgCkBX78kZmbADcBc59xlsVNTgNG549HA5NB1q4KaygaUDxnOR9lkNxvITj6ht1QYAoyjaYbIjc65C4O9eInMbFfgSWAOsDJXfCZNY6OTgN7AQuAg59x/UqlkgmopG1A+Wc5H2WQ3G8hOPlpeR0REgtMKByIiEpwaHxERCU6Nj4iIBKfGR0REglPjIyIiwanxERGR4NT4iIhIcP8Pr3BP6ZK9fTwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea8ad2ff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1,9):\n",
    "    plt.subplot(340+i)\n",
    "    plt.imshow(np.vstack([img.reshape(-1,) for img in mnist.train.images])[30+i*5000].reshape(28,28),cmap='gray_r')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## tf.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST with Softmax Regression\n",
    "The first half of exercise refers to TensorFlow tutorial. https://www.tensorflow.org/versions/r1.4/get_started/mnist/beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Placeholders\n",
    "We'll input when we ask TensorFlow to run a computation. We want to be able to input any number of MNIST images, each flattened into a 784-dimensional vector. We represent this as a 2-D tensor of floating-point numbers, with a shape [None, 784]. (Here None means that a dimension can be of any length.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Variables: Weights and biases\n",
    "A Variable is a modifiable tensor that lives in TensorFlow's graph of interacting operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model Implementation\n",
    "1. Multiply x by W\n",
    "2. Add b\n",
    "3. Apply tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Cross-entropy placeholder \n",
    "new placeholder to input the correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Cross-entropy function\n",
    "\n",
    "API reference\n",
    "- tf.reduce_mean https://www.tensorflow.org/api_docs/python/tf/reduce_mean\n",
    "- tf.nn.softmax_cross_entropy_with_logits_v2 https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), axis=[1]))\n",
    "\n",
    "## cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Launch model\n",
    "in an InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Train\n",
    "\n",
    "Load 100 training examples in each training iteration and train 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "#### 12. Comparison prediction and the truth\n",
    "\n",
    "- tf.argmax is an extremely useful function which gives you the index of the highest entry in a tensor along some axis\n",
    "- tf.equal to check if our prediction matches the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us a list of booleans. To determine what fraction are correct, we cast to floating point numbers and then take the mean. For example, [True, False, True, True] would become [1,0,1,1] which would become 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST with CNN\n",
    "\n",
    "The second half of exercise refers to TensorFlow tutorial with minor modification. https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros\n",
    "\n",
    "#### 9-1. Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-2. Convolution and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-3. 1st Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-4. 2nd Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-5. Densely Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-6. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-7. Readout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9-8. Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-df758a59bf08>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "step 0, training accuracy 0.18\n",
      "step 100, training accuracy 0.76\n",
      "step 200, training accuracy 0.9\n",
      "step 300, training accuracy 0.96\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-df758a59bf08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m### Replaced the original Tensorflow code to prevent GPU memory error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \"\"\"\n\u001b[0;32m-> 2285\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4934\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4936\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Do not replace tf.nn.softmax_cross_entropy_with_logits API to v2, causing crash\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "### Replaced the original Tensorflow code to prevent GPU memory error\n",
    "### https://stackoverflow.com/questions/39076388/tensorflow-deep-mnist-resource-exhausted-oom-when-allocating-tensor-with-shape\n",
    "\n",
    "for i in range(100):\n",
    "    testSet = mnist.test.next_batch(50)\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={ x: testSet[0], y_: testSet[1], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
